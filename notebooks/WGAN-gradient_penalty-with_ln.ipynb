{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WGAN-gp-ln_DCGAN_LSUN.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "mount_file_id": "1036zl_MkRD6Hfdm1FK0vUuAJNL44KX0V",
      "authorship_tag": "ABX9TyOKtJsjA1q4g7X5KEa1LqHc"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh5taXsOTvBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#http://dl.yf.io/lsun/scenes/\n",
        "\"\"\"\n",
        "bridge_train_lmdb.zip                              12-Mar-2017 23:01     15G\n",
        "church_outdoor_train_lmdb.zip                      12-Mar-2017 23:03      2G\n",
        "classroom_train_lmdb.zip                           12-Mar-2017 23:04      3G\n",
        "conference_room_train_lmdb.zip                     12-Mar-2017 23:06      4G\n",
        "dining_room_train_lmdb.zip                         12-Mar-2017 23:12     11G\n",
        "restaurant_train_lmdb.zip                          12-Mar-2017 23:46     13G\n",
        "tower_train_lmdb.zip                               12-Mar-2017 23:52     11G\n",
        "\"\"\"\n",
        "%mkdir data\n",
        "!git clone https://github.com/fyu/lsun\n",
        "%cd lsun\n",
        "!python download.py -c conference_room -o ../data/ \n",
        "%cd ../data\n",
        "!unzip conference_room_train_lmdb.zip && rm conference_room_train_lmdb.zip\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7UFhGQ-NAuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvMkVStNcZbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_PATH = \"/content/data/\"\n",
        "log_PATH = os.path.join(\"/gdrive\",\"My Drive\",\"notebooks\", \"logs\",\"wgan-gp\")\n",
        "modelName = \"WGAN-gp_DCGAN_ln_conference_lsun\"\n",
        "\n",
        "batch_size =64\n",
        "workers = 2\n",
        "epochs = 15\n",
        "\n",
        "latent_size=100\n",
        "\n",
        "gf_dim = 64\n",
        "df_dim = 64\n",
        "\n",
        "in_h = 64\n",
        "in_w =64\n",
        "c_dim = 3\n",
        "\n",
        "n_critic = 5 # the number of iterations of the critic per generator iteration\n",
        "\n",
        "learning_rate = 0.0001\n",
        "beta1=0.5\n",
        "beta2=0.9\n",
        "\n",
        "gp_lambda = 10\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "manualSeed = 3734\n",
        "print(\"Random Seed: \",manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_vSt4cyTvAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize((in_h,in_w)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
        "     ]\n",
        ")\n",
        "def transform_inverse (y):\n",
        "  t= None\n",
        "  if y.size()[0]==1:#1-dim\n",
        "    t=torchvision.transforms.Normalize((-1,),(2,))\n",
        "  else :#3-dim\n",
        "    t=torchvision.transforms.Normalize((-1,-1,-1),(2,2,2))\n",
        "  return t(y)\n",
        "\n",
        "def batch_transform_inverse(y):\n",
        "  x = y.new(*y.size())\n",
        "  if y.size()[1]==1:\n",
        "    x[:, 0, :, :] = y[:, 0, :, :] * 2 - 1\n",
        "  else:\n",
        "    x[:, 0, :, :] = y[:, 0, :, :] * 2 - 1\n",
        "    x[:, 1, :, :] = y[:, 1, :, :] * 2 - 1 \n",
        "    x[:, 2, :, :] = y[:, 2, :, :] * 2 - 1\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMux3QSITu_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lsun_dataset=torchvision.datasets.LSUN(root = data_PATH,\n",
        "                                             classes= ['conference_room_train'],\n",
        "                                 transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(lsun_dataset,batch_size=batch_size,\n",
        "                                          shuffle =True, num_workers=workers)\n",
        "print(lsun_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3ej9H9Ycmzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_batch = next(iter(train_loader))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis('off')\n",
        "plt.title('Training Images')\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device),padding=2, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "print(real_batch[0].size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV4GfSUZl2xV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "def norm_layer(out_shape, mode='bn'):\n",
        "  if len(out_shape)==4:\n",
        "    out_shape = out_shape[1:]\n",
        "  if mode=='bn':\n",
        "    return nn.BatchNorm2d(out_shape[0],momentum=0.1,eps=1e-5)\n",
        "  elif mode == 'ln':\n",
        "    return nn.LayerNorm(out_shape[:],eps=1e-5)\n",
        "  elif mode == 'in':\n",
        "    return nn.InstanceNorm2d(output_shape[0],momentum=0.1,eps=1e-5)\n",
        "  else:\n",
        "    raise NameError(\"'%s' is not valid normalization type\"%mode)\n",
        "\n",
        "\n",
        "def conv_bn_layer(in_channels,out_channels,kernel_size,stride=1,padding=0):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels,out_channels,kernel_size,stride=stride,padding=padding,bias=False),\n",
        "        nn.BatchNorm2d(out_channels,momentum=0.1,eps=1e-5),\n",
        "    )\n",
        "\n",
        "\n",
        "def tconv_bn_layer(in_channels,out_channels,kernel_size,stride=1,padding=0):\n",
        "  return nn.Sequential(\n",
        "      nn.ConvTranspose2d(in_channels,out_channels,kernel_size,stride=stride,padding=padding,bias=False),\n",
        "      nn.BatchNorm2d(out_channels,momentum=0.1,eps=1e-5),\n",
        "  )\n",
        "def tconv_layer(in_channels,out_channels,kernel_size,stride=1,padding=0):\n",
        "  return nn.ConvTranspose2d(in_channels,out_channels,kernel_size,stride=stride,padding=padding)\n",
        "\n",
        "def conv_layer(in_channels,out_channels,kernel_size,stride=1,padding=0):\n",
        "    return nn.Conv2d(in_channels,out_channels,kernel_size,stride=stride,padding=padding)\n",
        "\n",
        "def fc_layer(in_features,out_features):\n",
        "  return nn.Linear(in_features,out_features)\n",
        "\n",
        "def fc_bn_layer(in_features,out_features):\n",
        "  return nn.Sequential(\n",
        "      nn.Linear(in_features,out_features,bias=False),\n",
        "      nn.BatchNorm1d(out_features)\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LLwmd9Pc0dg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_out_size_same(size, stride):\n",
        "  return int(math.ceil(float(size) / float(stride)))\n",
        "s_h, s_w = in_h, in_w\n",
        "s_h2, s_w2 = conv_out_size_same(s_h, 2), conv_out_size_same(s_w, 2)\n",
        "s_h4, s_w4 = conv_out_size_same(s_h2, 2), conv_out_size_same(s_w2, 2)\n",
        "s_h8, s_w8 = conv_out_size_same(s_h4, 2), conv_out_size_same(s_w4, 2)\n",
        "s_h16, s_w16 = conv_out_size_same(s_h8, 2), conv_out_size_same(s_w8, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OrzwhZjeN0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator,self).__init__()\n",
        "    self.fc_bn_layer1 = fc_bn_layer(latent_size,s_h16*s_w16*gf_dim*8)\n",
        "    self.up_sample_layer2 = tconv_bn_layer(gf_dim*8,gf_dim*4,4,stride=2,padding=1)\n",
        "    self.up_sample_layer3 = tconv_bn_layer(gf_dim*4,gf_dim*2,4,stride=2,padding=1)\n",
        "    self.up_sample_layer4 = tconv_bn_layer(gf_dim*2,gf_dim,4,stride=2,padding=1)\n",
        "    self.up_sample_layer5 = tconv_layer(gf_dim,c_dim,4,stride=2,padding=1)\n",
        "    self.tanh = nn.Tanh()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc_bn_layer1(x))\n",
        "    x = x.view(-1,gf_dim*8,s_h16,s_w16)\n",
        "    x = F.relu(self.up_sample_layer2(x))\n",
        "    x = F.relu(self.up_sample_layer3(x))\n",
        "    x = F.relu(self.up_sample_layer4(x))\n",
        "    x = self.tanh(self.up_sample_layer5(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bi0U0m5n4dM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "batch normalization changes the form of the discriminator's problem from mapping a single input to a single output to mapping from an entire batch of inputs to a batch of outputs.\n",
        "Since we penalize the norm of the critic's gradient with respect to each input independently, and not the entire batch, our penalized training objective is no longer valid in this setting.\n",
        "\"\"\"\n",
        "class Critic(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Critic,self).__init__()\n",
        "    self.down_sample_layer1 = conv_layer(c_dim,df_dim,4,stride=2,padding=1)\n",
        "    self.down_sample_layer2 = conv_layer(df_dim,df_dim*2,4,stride=2,padding=1)\n",
        "    self.norm_layer2 = norm_layer([df_dim*2,s_h4,s_w4],mode='ln')\n",
        "    self.down_sample_layer3 = conv_layer(df_dim*2,df_dim*4,4,stride=2,padding=1)\n",
        "    self.norm_layer3 = norm_layer([df_dim*4,s_h8,s_w8],mode='ln')\n",
        "    self.down_sample_layer4 = conv_layer(df_dim*4,df_dim*8,4,stride=2,padding=1)\n",
        "    self.norm_layer4 = norm_layer([df_dim*8,s_h16,s_w16],mode='ln')\n",
        "    self.fc_layer5 = fc_layer(df_dim*8*s_h16*s_w16,1)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.leaky_relu(self.down_sample_layer1(x),0.2)\n",
        "    x = F.leaky_relu(self.norm_layer2(self.down_sample_layer2(x)),0.2)\n",
        "    x = F.leaky_relu(self.norm_layer3(self.down_sample_layer3(x)),0.2)\n",
        "    x = F.leaky_relu(self.norm_layer4(self.down_sample_layer4(x)),0.2)\n",
        "    x = x.flatten(1)\n",
        "    x = self.fc_layer5(x)\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6rLRcDzerPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "G = Generator().to(device)\n",
        "fw = Critic().to(device)\n",
        "\n",
        "G_optimizer = optim.Adam(G.parameters(),lr=learning_rate,betas=(beta1,beta2),weight_decay=1e-3) # when using layer(or batch) normalization, weight decaying is recommended\n",
        "critic_optimizer = optim.Adam(fw.parameters(),lr=learning_rate,betas=(beta1,beta2),weight_decay=1e-3)\n",
        "\n",
        "L2_criterion = nn.MSELoss()\n",
        "\n",
        "fixed_noise = torch.randn(batch_size, latent_size,device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmNAyZJ9xhyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "  classname = m.__class__.__name__\n",
        "  if classname.find('Conv')!=-1:\n",
        "    nn.init.normal_(m.weight.data,0.0,0.02)\n",
        "  elif classname.find('Norm')!=-1:\n",
        "    nn.init.normal_(m.weight.data,1.0,0.02)\n",
        "\n",
        "print(G.apply(weights_init))\n",
        "print(fw.apply(weights_init))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2xDUg479EMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  fake_batch=G(fixed_noise)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis('off')\n",
        "plt.title('fake Images Before learning')\n",
        "plt.imshow(np.transpose(vutils.make_grid(fake_batch.to(device).view(64,c_dim,in_h,in_w),padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2T4HqQeHgVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_list = []\n",
        "\n",
        "G_losses = []\n",
        "critic_losses = []\n",
        "\n",
        "w_losses = []\n",
        "gp_losses =[]\n",
        "\n",
        "iter_per_plot = 500\n",
        "plot_per_eps=(int(len(train_loader)/iter_per_plot))\n",
        "\n",
        "transform_PIL=transforms.ToPILImage()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoifK0ncmbe8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "def log_list_save(l,file_name):\n",
        "  with open(os.path.join(log_PATH ,file_name+\".logs\"), \"wb\") as fp:\n",
        "    pickle.dump(l, fp)\n",
        "\n",
        "def log_list_load(file_name):\n",
        "  with open(os.path.join(log_PATH ,file_name+\".logs\"), \"rb\") as fp:\n",
        "    return pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us1noJS_oRSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.autograd as autograd\n",
        "from torch.autograd import Variable\n",
        "\n",
        "for ep in range(epochs):\n",
        "  for i, (real_data, _) in enumerate(train_loader):\n",
        "    b_size=real_data.shape[0]\n",
        "    real_data = real_data.to(device)\n",
        "    z = torch.randn(b_size,latent_size).to(device)\n",
        "    fake_data = G(z)\n",
        "    alpha = torch.rand([b_size,1,1,1],device=device)#for sampling_distribution\n",
        "    alpha = alpha.expand(real_data.size())\n",
        "\n",
        "    #Train critic function\n",
        "    fw.zero_grad()\n",
        "\n",
        "    # calculate gradient penalty\n",
        "\n",
        "    interpolates = alpha * real_data.data  + (1-alpha)*fake_data.data\n",
        "    interpolates=Variable(interpolates,requires_grad=True)\n",
        "\n",
        "    disc_interpolates= fw(interpolates)\n",
        "\n",
        "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
        "                                  grad_outputs=torch.ones(disc_interpolates.size(),device=device),\n",
        "                                  create_graph=True)[0].view(interpolates.size(0),-1)\n",
        "    slopes = gradients.norm(2,dim=1)\n",
        "    lipschitz_gradient_norm=torch.ones(slopes.size(),device=device)\n",
        "    \n",
        "    loss_gp = gp_lambda*L2_criterion(slopes,lipschitz_gradient_norm)\n",
        "    \n",
        "    real_critic = fwx = fw(real_data)\n",
        "    fake_critic = fwg = fw(fake_data.detach())\n",
        "    loss_w = -(fwx.mean()-fwg.mean())\n",
        "\n",
        "    loss_critic = loss_w + loss_gp\n",
        "    loss_critic.backward()\n",
        "    critic_optimizer.step()\n",
        "\n",
        "    #Train G\n",
        "    if (i+1)%n_critic==0:\n",
        "      G.zero_grad()\n",
        "      fwg = fw(fake_data)\n",
        "      \n",
        "      loss_G = -fwg.mean()\n",
        "\n",
        "      loss_G.backward()\n",
        "      G_optimizer.step()\n",
        "\n",
        "    if (i+1)%iter_per_plot == 0:\n",
        "      print('Epoch [{}/{}], Step [{}/{}], critic_loss: {:.4f}, g_loss: {:.4f}, fw(x): {:.4f}, fw(G(z)): {:.4f}, gp : {:.4f} ' \n",
        "            .format(ep, epochs, i+1, len(train_loader), loss_critic.item(),  fake_critic.mean().item(), \n",
        "                    real_critic.mean().item(), fake_critic.mean().item(),loss_gp.item()))\n",
        "      G_losses.append(fake_critic.mean().item())\n",
        "      critic_losses.append(loss_critic.item())\n",
        "\n",
        "      w_losses.append(loss_w.item())\n",
        "      gp_losses.append(loss_gp.item())\n",
        "\n",
        "      with torch.no_grad():\n",
        "        G.eval()\n",
        "        fake = G(fixed_noise).detach().cpu()\n",
        "        img_list.append(vutils.make_grid(torch.reshape(fake,(b_size,c_dim,in_h,in_w))[:64], padding=2, normalize=True))\n",
        "        transform_PIL(img_list[-1]).save(os.path.join(log_PATH,str(ep)+modelName+\"_Last.png\"))\n",
        "        G.train()\n",
        "\n",
        "      log_list_save(G_losses,os.path.join(log_PATH,\"G_losses\"))\n",
        "      log_list_save(critic_losses,os.path.join(log_PATH,\"critic_losses\"))\n",
        "      log_list_save(w_losses,os.path.join(log_PATH,\"w_losses\"))\n",
        "      log_list_save(gp_losses,os.path.join(log_PATH,\"gp_losses\"))\n",
        "\n",
        "      torch.save(G.state_dict(),os.path.join(log_PATH,\"G\"+modelName+\".pth\"))\n",
        "      torch.save(fw.state_dict(),os.path.join(log_PATH,\"fw\"+modelName+\".pth\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzjqXhOfJwB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  G.eval()\n",
        "  fake_batch=G(fixed_noise)\n",
        "  G.train()\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis('off')\n",
        "plt.title('fake Images')\n",
        "plt.imshow(np.transpose(vutils.make_grid(fake_batch.to(device)[:64].view(64,c_dim,in_h,in_w),padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGIJybe6VgIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_batch = next(iter(train_loader))\n",
        "\n",
        "# Plot the real images\n",
        "fig=plt.figure(figsize=(15,8))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "# Plot the fake images from the last epoch\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake Images\")\n",
        "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "\n",
        "fig.savefig(os.path.join(log_PATH,\"Compare\"))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcpVbKGhnTyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in short_img_list]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "HTML(ani.to_jshtml())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZENEg37EfPJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "transform_PIL=transforms.ToPILImage()\n",
        "\n",
        "p_img_list = [transform_PIL(p_image) for p_image in short_img_list]\n",
        "p_img_list[0].save(os.path.join(log_PATH,modelName+'s.gif'), save_all=True,append_images=p_img_list[1:], optimize=False, duration=0.5, loop=0)\n",
        "p_img_list[-1].save(os.path.join(log_PATH,modelName+\"_last_result.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MWmE6l_5yUDs",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  G.eval()\n",
        "  random_noise=torch.randn(batch_size,latent_size,device=device)\n",
        "  fake=G(random_noise)\n",
        "  G.train()\n",
        "fake = fake.squeeze().cpu()\n",
        "fake_image=transform_inverse(fake[0])\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(np.transpose(fake_image,(1,2,0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14_lnF5oJa8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title(\"Losses\")\n",
        "epsilon = 1/plot_per_eps\n",
        "X = np.array(range(plot_per_eps*50))/plot_per_eps\n",
        "\n",
        "plt.plot(X,G_losses,label=\"G loss\")\n",
        "plt.plot(X,i_critic_losses,label=\"critic loss\")\n",
        "plt.legend(loc=2)\n",
        "plt.xticks(np.arange(0,50+1,5)) \n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "#plt.show()\n",
        "# plt.savefig(os.path.join(modelName+\"_loss_figure.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVVFlWgWJNfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title(\"Losses\")\n",
        "epsilon = 1/plot_per_eps\n",
        "X = np.array(range(plot_per_eps*50))/plot_per_eps\n",
        "\n",
        "plt.plot(X,i_critic_losses,label=\"critic loss\")\n",
        "plt.plot(X,gp_losses,label=\"gp loss\")\n",
        "plt.legend(loc=2)\n",
        "plt.xticks(np.arange(0,50+1,5)) \n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "#plt.show()\n",
        "plt.savefig(os.path.join(modelName+\"_loss_figure_gp,critic.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlZGsqwgKW9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title(\"Losses\")\n",
        "epsilon = 1/plot_per_eps\n",
        "X = np.array(range(plot_per_eps*50))/plot_per_eps\n",
        "\n",
        "plt.plot(X,G_losses,label=\"G loss\")\n",
        "plt.legend(loc=2)\n",
        "plt.xticks(np.arange(0,50+1,5)) \n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "#plt.show()\n",
        "plt.savefig(os.path.join(modelName+\"G_loss_figure.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eYsOW7uKgzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title(\"Losses\")\n",
        "epsilon = 1/plot_per_eps\n",
        "X = np.array(range(plot_per_eps*50))/plot_per_eps\n",
        "plt.plot(X,i_critic_losses,label=\"critic loss\")\n",
        "\n",
        "plt.legend(loc=2)\n",
        "plt.xticks(np.arange(0,50+1,5)) \n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "#plt.show()\n",
        "plt.savefig(os.path.join(modelName+\"critic_loss_figure.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrIFq8TPuAC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title(\"Losses\")\n",
        "epsilon = 1/plot_per_eps\n",
        "X = np.array(range(plot_per_eps*50))/plot_per_eps\n",
        "plt.plot(X,gp_losses,label=\"critic loss\")\n",
        "\n",
        "plt.legend(loc=2)\n",
        "plt.xticks(np.arange(0,50+1,5)) \n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "#plt.show()\n",
        "plt.savefig(os.path.join(modelName+\"gp_loss_figure.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_HC2ZtBMg0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(G.state_dict(),os.path.join(log_PATH,\"./G_\"+modelName+\".pth\"))\n",
        "G.load_state_dict(torch.load(os.path.join(log_PATH,(\"G_\"+modelName+\".pth\"))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-Qag7s-N7uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(fw.state_dict(),os.path.join(log_PATH,\"./critic_\"+modelName+\".pth\"))\n",
        "fw.load_state_dict(torch.load(os.path.join(log_PATH,(\"critic_\"+modelName+\".pth\"))))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}